{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"reworked_backprop.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1iVKUCfWIzyQjrHAU8xeapy0T0Zg8YDOQ","authorship_tag":"ABX9TyP0wAw+EEFDpwg3dTvZc/xL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1498ceada63841b7aaf4f996a2db2c3c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_62ba6574fa2d43a1bb2af96af609b311","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_399d5a75cda04110911cb37aad6ea766","IPY_MODEL_fe8ca5464f4e4aad89450c9ee60509df"]}},"62ba6574fa2d43a1bb2af96af609b311":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"399d5a75cda04110911cb37aad6ea766":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9cbe44d4059644cd96e4c73f01af2122","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":871891,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":871891,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_29ba47a9d15c435cb3e78ebc0ec3a7bd"}},"fe8ca5464f4e4aad89450c9ee60509df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_39d9df43498748ada2b1d522446ebd02","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 872k/872k [00:00&lt;00:00, 1.77MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1098aa7970644ac1995c4d25f7968b9f"}},"9cbe44d4059644cd96e4c73f01af2122":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"29ba47a9d15c435cb3e78ebc0ec3a7bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"39d9df43498748ada2b1d522446ebd02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1098aa7970644ac1995c4d25f7968b9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9591ad01d170442994c22182c61a4fc1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6f619fb63de34e66ba773723f36d0b29","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_88536be4a0f741b0bcfa16daf8ccef93","IPY_MODEL_01bb743442834c2e944bee04911272de"]}},"6f619fb63de34e66ba773723f36d0b29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"88536be4a0f741b0bcfa16daf8ccef93":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_71cc88eea8334615bd50fc19e4cac179","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a4e7cba6fe8c4de1b74bbbd1fc456b9a"}},"01bb743442834c2e944bee04911272de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a301e620691d47d3ac503b450092efe9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:16&lt;00:00, 37.8B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f191f17360ed4a7d9b4837e1e9742208"}},"71cc88eea8334615bd50fc19e4cac179":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a4e7cba6fe8c4de1b74bbbd1fc456b9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a301e620691d47d3ac503b450092efe9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f191f17360ed4a7d9b4837e1e9742208":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2c27d3ddcf0541fda53b9ec272b29850":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_af526905b3d445b9a96c0457a73dc1d7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_669200995bce47ecba8126dbbff44c79","IPY_MODEL_a5020bb7012e4662ab853580eb7d182e"]}},"af526905b3d445b9a96c0457a73dc1d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"669200995bce47ecba8126dbbff44c79":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a1167ca832b04dcfbf670d0159c7f6bb","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":999358484,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":999358484,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_52f8ae0623f64784947b001b7d3023bb"}},"a5020bb7012e4662ab853580eb7d182e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6ac37aafd01a4ce8b5095ff307d22b51","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 999M/999M [00:16&lt;00:00, 61.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0b97837183a24a62a21eb5f9e993344c"}},"a1167ca832b04dcfbf670d0159c7f6bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"52f8ae0623f64784947b001b7d3023bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6ac37aafd01a4ce8b5095ff307d22b51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0b97837183a24a62a21eb5f9e993344c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"auP7yfRbBKx5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":559},"executionInfo":{"status":"ok","timestamp":1596397917239,"user_tz":-330,"elapsed":45542,"user":{"displayName":"Jinen Setpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gipe8JNdbgo-vHXJYvyjvR1hfRzal9h_g3W2DwUWHY=s64","userId":"01891518843930644308"}},"outputId":"c32d442e-1209-4b0d-8708-e2e87565ea76"},"source":["! pip install -q tensorflow numpy pandas scikit-learn mlxtend dataprep transformers\n","! cp drive/My\\ Drive/Colab\\ Notebooks/*.csv ./\n","! cp drive/My\\ Drive/Colab\\ Notebooks/*.pkl ./"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 92kB 3.4MB/s \n","\u001b[K     |████████████████████████████████| 778kB 17.8MB/s \n","\u001b[K     |████████████████████████████████| 512kB 37.5MB/s \n","\u001b[K     |████████████████████████████████| 5.5MB 28.3MB/s \n","\u001b[K     |████████████████████████████████| 2.2MB 46.9MB/s \n","\u001b[K     |████████████████████████████████| 71kB 6.9MB/s \n","\u001b[K     |████████████████████████████████| 1.4MB 44.1MB/s \n","\u001b[K     |████████████████████████████████| 8.6MB 15.3MB/s \n","\u001b[K     |████████████████████████████████| 368kB 44.7MB/s \n","\u001b[K     |████████████████████████████████| 61kB 7.2MB/s \n","\u001b[K     |████████████████████████████████| 798kB 43.6MB/s \n","\u001b[K     |████████████████████████████████| 3.0MB 43.6MB/s \n","\u001b[K     |████████████████████████████████| 1.1MB 41.9MB/s \n","\u001b[K     |████████████████████████████████| 890kB 47.4MB/s \n","\u001b[K     |████████████████████████████████| 51kB 7.0MB/s \n","\u001b[K     |████████████████████████████████| 655kB 39.4MB/s \n","\u001b[K     |████████████████████████████████| 102kB 658kB/s \n","\u001b[?25h  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for jsonpath-ng (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for bokeh (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for locket (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: panel 0.9.7 has requirement bokeh>=2.1, but you'll have bokeh 2.0.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement tornado~=5.1.0; python_version >= \"3.0\", but you'll have tornado 5.0.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: distributed 2.22.0 has requirement cloudpickle>=1.5.0, but you'll have cloudpickle 1.3.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aX-OxOSTBXQS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596397919645,"user_tz":-330,"elapsed":2387,"user":{"displayName":"Jinen Setpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gipe8JNdbgo-vHXJYvyjvR1hfRzal9h_g3W2DwUWHY=s64","userId":"01891518843930644308"}}},"source":["import pandas as pd\n","\n","df = pd.read_csv('dankmemes_task1_train.csv')\n","embedding = pd.read_csv('dankmemes_task1_train_embeddings.csv', header=None)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ibcTrVTmBrCN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596397921574,"user_tz":-330,"elapsed":4307,"user":{"displayName":"Jinen Setpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gipe8JNdbgo-vHXJYvyjvR1hfRzal9h_g3W2DwUWHY=s64","userId":"01891518843930644308"}}},"source":["import tensorflow as tf\n","from tensorflow.keras import Model\n","\n","class MyModel(Model):\n","  def __init__(self):\n","    super(MyModel, self).__init__()\n","    self.dense1 = tf.keras.layers.Dense(1024, activation=tf.keras.activations.relu)\n","    self.drop = tf.keras.layers.Dropout(rate=0.5)\n","    self.dense2 = tf.keras.layers.Dense(512, activation=tf.keras.activations.relu)\n","    self.dense3 = tf.keras.layers.Dense(128, activation=tf.keras.activations.relu)\n","    self.dense4 = tf.keras.layers.Dense(32, activation=tf.keras.activations.relu)\n","    self.dense5 = tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid) \n","\n","  def call(self, x):\n","    x = self.dense1(x)\n","    x = self.drop(x)\n","    x = self.dense2(x)\n","    x = self.dense3(x)\n","    x = self.dense4(x)\n","    return self.dense5(x)\n","\n","model = MyModel()"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"JRzGL7_6FjqF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596397921585,"user_tz":-330,"elapsed":4310,"user":{"displayName":"Jinen Setpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gipe8JNdbgo-vHXJYvyjvR1hfRzal9h_g3W2DwUWHY=s64","userId":"01891518843930644308"}}},"source":["loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n","optimizer = tf.keras.optimizers.RMSprop()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"04qDSq6UGGyW","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596397921587,"user_tz":-330,"elapsed":4305,"user":{"displayName":"Jinen Setpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gipe8JNdbgo-vHXJYvyjvR1hfRzal9h_g3W2DwUWHY=s64","userId":"01891518843930644308"}}},"source":["train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n","\n","test_loss = tf.keras.metrics.Mean(name='test_loss')\n","test_accuracy = tf.keras.metrics.BinaryAccuracy(name='test_accuracy')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Wx0v9sXGRzw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596397921591,"user_tz":-330,"elapsed":4302,"user":{"displayName":"Jinen Setpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gipe8JNdbgo-vHXJYvyjvR1hfRzal9h_g3W2DwUWHY=s64","userId":"01891518843930644308"}}},"source":["@tf.function\n","def train_step(images, labels):\n","  with tf.GradientTape() as tape:\n","    predictions = model(images, training=True)\n","    loss = loss_object(labels, predictions)\n","  gradients = tape.gradient(loss, model.trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","  train_loss(loss)\n","  train_accuracy(labels, predictions)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ln_uIdPEGapm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596397921594,"user_tz":-330,"elapsed":4297,"user":{"displayName":"Jinen Setpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gipe8JNdbgo-vHXJYvyjvR1hfRzal9h_g3W2DwUWHY=s64","userId":"01891518843930644308"}}},"source":["@tf.function\n","def test_step(images, labels):\n","  predictions = model(images, training=False)\n","  t_loss = loss_object(labels, predictions)\n","\n","  test_loss(t_loss)\n","  test_accuracy(labels, predictions)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"sKK3zJgZGdbr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596397921596,"user_tz":-330,"elapsed":4294,"user":{"displayName":"Jinen Setpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gipe8JNdbgo-vHXJYvyjvR1hfRzal9h_g3W2DwUWHY=s64","userId":"01891518843930644308"}}},"source":["def ds_from_df(df, shuffle=True, batch_size=32):\n","  dataframe = dataframe.copy()\n","  labels = dataframe.pop('Meme')\n","  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n","  if shuffle:\n","    ds = ds.shuffle(buffer_size=len(dataframe))\n","  ds = ds.batch(batch_size)\n","  return ds"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"tWG59jgqHVuQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596397924970,"user_tz":-330,"elapsed":7661,"user":{"displayName":"Jinen Setpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gipe8JNdbgo-vHXJYvyjvR1hfRzal9h_g3W2DwUWHY=s64","userId":"01891518843930644308"}}},"source":["import numpy as np\n","\n","X, y = np.array([embedding[1][i].split() for i in range(1600)]).astype(float), df[['Meme']].values"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"1nad8SZqN9Mh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596397924978,"user_tz":-330,"elapsed":7664,"user":{"displayName":"Jinen Setpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gipe8JNdbgo-vHXJYvyjvR1hfRzal9h_g3W2DwUWHY=s64","userId":"01891518843930644308"}}},"source":["def create_map():\n","  temp = df[['Visual']].values\n","  counter = 0\n","  map = {}\n","  for i in temp:\n","    for j in i[0].split():\n","      if j.strip(',') not in map and j.strip(',') != '0':\n","        map[j.strip(',')] = counter\n","        counter += 1\n","  return map"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"M5z7SNzLS3KI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596397924981,"user_tz":-330,"elapsed":7662,"user":{"displayName":"Jinen Setpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gipe8JNdbgo-vHXJYvyjvR1hfRzal9h_g3W2DwUWHY=s64","userId":"01891518843930644308"}}},"source":["def ohe(map):\n","  one_hot_encode = []\n","  temp = df[['Visual']].values\n","\n","  for i in temp:\n","    arr = list(np.zeros(len(map),dtype=int))\n","    for j in i[0].split():\n","      if j.strip(',') != '0':\n","        arr[map[j.strip(',')]] = 1\n","    one_hot_encode.append(arr)\n","  return np.array(one_hot_encode)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"2j8VeymhHdTa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":288,"referenced_widgets":["1498ceada63841b7aaf4f996a2db2c3c","62ba6574fa2d43a1bb2af96af609b311","399d5a75cda04110911cb37aad6ea766","fe8ca5464f4e4aad89450c9ee60509df","9cbe44d4059644cd96e4c73f01af2122","29ba47a9d15c435cb3e78ebc0ec3a7bd","39d9df43498748ada2b1d522446ebd02","1098aa7970644ac1995c4d25f7968b9f","9591ad01d170442994c22182c61a4fc1","6f619fb63de34e66ba773723f36d0b29","88536be4a0f741b0bcfa16daf8ccef93","01bb743442834c2e944bee04911272de","71cc88eea8334615bd50fc19e4cac179","a4e7cba6fe8c4de1b74bbbd1fc456b9a","a301e620691d47d3ac503b450092efe9","f191f17360ed4a7d9b4837e1e9742208","2c27d3ddcf0541fda53b9ec272b29850","af526905b3d445b9a96c0457a73dc1d7","669200995bce47ecba8126dbbff44c79","a5020bb7012e4662ab853580eb7d182e","a1167ca832b04dcfbf670d0159c7f6bb","52f8ae0623f64784947b001b7d3023bb","6ac37aafd01a4ce8b5095ff307d22b51","0b97837183a24a62a21eb5f9e993344c"]},"executionInfo":{"status":"ok","timestamp":1596397953192,"user_tz":-330,"elapsed":35864,"user":{"displayName":"Jinen Setpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gipe8JNdbgo-vHXJYvyjvR1hfRzal9h_g3W2DwUWHY=s64","userId":"01891518843930644308"}},"outputId":"6757cdd1-e7b2-47df-91da-15aaac0936ce"},"source":["from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n","from transformers import BertTokenizer, TFBertModel\n","\n","def bert(texts):\n","  res = []\n","  for text in texts:\n","    input_ids = tf.constant(tokenizer.encode(text))[None, :]\n","    res.append(np.array(brt(input_ids)[1]).ravel())\n","  return np.array(res)\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n","brt = TFBertModel.from_pretrained('bert-base-multilingual-uncased')\n","ssc = StandardScaler()\n","mms = MinMaxScaler()"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1498ceada63841b7aaf4f996a2db2c3c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=871891.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9591ad01d170442994c22182c61a4fc1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c27d3ddcf0541fda53b9ec272b29850","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=999358484.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-uncased.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"RSFo01qhHY0s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":172},"executionInfo":{"status":"ok","timestamp":1596397953197,"user_tz":-330,"elapsed":35864,"user":{"displayName":"Jinen Setpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gipe8JNdbgo-vHXJYvyjvR1hfRzal9h_g3W2DwUWHY=s64","userId":"01891518843930644308"}},"outputId":"50d1af32-59e5-4330-a961-50da6fcfb270"},"source":["import pickle\n","from datetime import date\n","\n","temp = mms.fit_transform(np.array([(date(int(i[0].split('-')[0]), int(i[0].split('-')[1]), int(i[0].split('-')[2])) - date(2015, 1, 1)).days for i in df[['Date']].values.tolist()]).reshape(1600, 1))\n","print(temp.shape)\n","X = np.hstack((X, temp))\n","print(X.shape)\n","\n","temp = ssc.fit_transform(df[['Engagement']].values)\n","print(temp.shape)\n","X = np.hstack((X, temp))\n","print(X.shape)\n","\n","temp = ohe(create_map())\n","print(temp.shape)\n","X = np.hstack((X, temp))\n","print(X.shape)\n","\n","temp = pickle.load(open('bert_embeddings.pkl', 'rb'))\n","print(temp.shape)\n","X = np.hstack((X, temp))\n","print(X.shape)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["(1600, 1)\n","(1600, 2049)\n","(1600, 1)\n","(1600, 2050)\n","(1600, 71)\n","(1600, 2121)\n","(1600, 768)\n","(1600, 2889)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"77oUZHfJHpV3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596397953201,"user_tz":-330,"elapsed":35862,"user":{"displayName":"Jinen Setpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gipe8JNdbgo-vHXJYvyjvR1hfRzal9h_g3W2DwUWHY=s64","userId":"01891518843930644308"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n","ds_train = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n","ds_test = tf.data.Dataset.from_tensor_slices((X_test, y_test))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"T1Yl52BIH0-C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":56},"executionInfo":{"status":"ok","timestamp":1596397953202,"user_tz":-330,"elapsed":35857,"user":{"displayName":"Jinen Setpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gipe8JNdbgo-vHXJYvyjvR1hfRzal9h_g3W2DwUWHY=s64","userId":"01891518843930644308"}},"outputId":"8d8f5a0e-a07c-4ddf-a993-0feb133b6124"},"source":["print(ds_train)\n","print(ds_test)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["<TensorSliceDataset shapes: ((2889,), (1,)), types: (tf.float64, tf.int64)>\n","<TensorSliceDataset shapes: ((2889,), (1,)), types: (tf.float64, tf.int64)>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fiF3Ss4oH-cD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596397953205,"user_tz":-330,"elapsed":35855,"user":{"displayName":"Jinen Setpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gipe8JNdbgo-vHXJYvyjvR1hfRzal9h_g3W2DwUWHY=s64","userId":"01891518843930644308"}}},"source":["buffer_size = 10000\n","batch_size = 64\n","num_epochs = 100"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"sarCqMdvIRV6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596397953207,"user_tz":-330,"elapsed":35851,"user":{"displayName":"Jinen Setpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gipe8JNdbgo-vHXJYvyjvR1hfRzal9h_g3W2DwUWHY=s64","userId":"01891518843930644308"}}},"source":["ds_train = ds_train.shuffle(buffer_size=buffer_size,\n","                            reshuffle_each_iteration=False)\n","ds_test = ds_test.batch(batch_size)\n","ds_train = ds_train.batch(batch_size)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"PTRkOMruIS8I","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596398063441,"user_tz":-330,"elapsed":146079,"user":{"displayName":"Jinen Setpal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gipe8JNdbgo-vHXJYvyjvR1hfRzal9h_g3W2DwUWHY=s64","userId":"01891518843930644308"}},"outputId":"1860b856-2e03-4b66-9c7d-ad6c0e653df1"},"source":["for epoch in range(100):\n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  test_loss.reset_states()\n","  test_accuracy.reset_states()\n","\n","  for features, labels in ds_train:\n","    train_step(features, labels)\n","\n","  for test_features, test_labels in ds_test:\n","    test_step(test_features, test_labels)\n","\n","  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n","  print(template.format(epoch + 1,\n","                        train_loss.result(),\n","                        train_accuracy.result() * 100,\n","                        test_loss.result(),\n","                        test_accuracy.result() * 100))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer my_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n","\n","If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n","\n","To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n","\n","Epoch 1, Loss: 1.348555564880371, Accuracy: 55.078125, Test Loss: 0.6158968210220337, Test Accuracy: 71.25\n","Epoch 2, Loss: 0.6326921582221985, Accuracy: 66.640625, Test Loss: 0.5544939041137695, Test Accuracy: 72.1875\n","Epoch 3, Loss: 0.5839303731918335, Accuracy: 68.828125, Test Loss: 0.5584436058998108, Test Accuracy: 73.75\n","Epoch 4, Loss: 0.5754336714744568, Accuracy: 70.546875, Test Loss: 0.5646582841873169, Test Accuracy: 71.25\n","Epoch 5, Loss: 0.540873110294342, Accuracy: 74.53125, Test Loss: 0.5435935854911804, Test Accuracy: 75.9375\n","Epoch 6, Loss: 0.5373228788375854, Accuracy: 73.28125, Test Loss: 0.5740353465080261, Test Accuracy: 71.875\n","Epoch 7, Loss: 0.524396538734436, Accuracy: 73.59375, Test Loss: 0.5461360812187195, Test Accuracy: 71.875\n","Epoch 8, Loss: 0.5229019522666931, Accuracy: 75.46875, Test Loss: 0.5508495569229126, Test Accuracy: 71.875\n","Epoch 9, Loss: 0.49141401052474976, Accuracy: 75.46875, Test Loss: 0.5486132502555847, Test Accuracy: 72.8125\n","Epoch 10, Loss: 0.4952430725097656, Accuracy: 77.734375, Test Loss: 0.5430610775947571, Test Accuracy: 73.125\n","Epoch 11, Loss: 0.48762211203575134, Accuracy: 77.421875, Test Loss: 0.5436667203903198, Test Accuracy: 73.125\n","Epoch 12, Loss: 0.45177125930786133, Accuracy: 77.890625, Test Loss: 0.542201817035675, Test Accuracy: 75.0\n","Epoch 13, Loss: 0.4640982747077942, Accuracy: 76.875, Test Loss: 0.5404165387153625, Test Accuracy: 75.625\n","Epoch 14, Loss: 0.49857935309410095, Accuracy: 77.265625, Test Loss: 0.5572879314422607, Test Accuracy: 72.8125\n","Epoch 15, Loss: 0.4496983587741852, Accuracy: 78.828125, Test Loss: 0.5453470349311829, Test Accuracy: 74.375\n","Epoch 16, Loss: 0.4242664873600006, Accuracy: 79.453125, Test Loss: 0.5432549715042114, Test Accuracy: 76.25\n","Epoch 17, Loss: 0.43414339423179626, Accuracy: 80.46875, Test Loss: 0.5361889600753784, Test Accuracy: 75.0\n","Epoch 18, Loss: 0.42715662717819214, Accuracy: 80.390625, Test Loss: 0.5311279296875, Test Accuracy: 76.25\n","Epoch 19, Loss: 0.40997499227523804, Accuracy: 80.46875, Test Loss: 0.5388073325157166, Test Accuracy: 79.0625\n","Epoch 20, Loss: 0.39710181951522827, Accuracy: 81.71875, Test Loss: 0.5857923626899719, Test Accuracy: 74.375\n","Epoch 21, Loss: 0.3838554322719574, Accuracy: 81.875, Test Loss: 0.5492107272148132, Test Accuracy: 77.5\n","Epoch 22, Loss: 0.41610971093177795, Accuracy: 80.15625, Test Loss: 0.547653317451477, Test Accuracy: 77.8125\n","Epoch 23, Loss: 0.41489845514297485, Accuracy: 82.1875, Test Loss: 0.5335346460342407, Test Accuracy: 78.4375\n","Epoch 24, Loss: 0.35489553213119507, Accuracy: 82.734375, Test Loss: 0.6052287220954895, Test Accuracy: 76.25\n","Epoch 25, Loss: 0.38195720314979553, Accuracy: 83.515625, Test Loss: 0.5918368101119995, Test Accuracy: 75.625\n","Epoch 26, Loss: 0.34967517852783203, Accuracy: 83.984375, Test Loss: 0.5497552156448364, Test Accuracy: 75.625\n","Epoch 27, Loss: 0.3627910614013672, Accuracy: 82.265625, Test Loss: 0.550564169883728, Test Accuracy: 79.6875\n","Epoch 28, Loss: 0.33239465951919556, Accuracy: 85.0, Test Loss: 0.5529627799987793, Test Accuracy: 78.4375\n","Epoch 29, Loss: 0.37959662079811096, Accuracy: 83.125, Test Loss: 0.5390315055847168, Test Accuracy: 79.375\n","Epoch 30, Loss: 0.3201825022697449, Accuracy: 85.78125, Test Loss: 0.6838617324829102, Test Accuracy: 72.5\n","Epoch 31, Loss: 0.3288397192955017, Accuracy: 85.234375, Test Loss: 0.6893860697746277, Test Accuracy: 75.9375\n","Epoch 32, Loss: 0.40611162781715393, Accuracy: 83.75, Test Loss: 0.5610019564628601, Test Accuracy: 77.5\n","Epoch 33, Loss: 0.2961413860321045, Accuracy: 86.875, Test Loss: 0.5890892148017883, Test Accuracy: 78.4375\n","Epoch 34, Loss: 0.29515931010246277, Accuracy: 86.5625, Test Loss: 0.6636713743209839, Test Accuracy: 77.1875\n","Epoch 35, Loss: 0.30520203709602356, Accuracy: 85.703125, Test Loss: 0.6396808624267578, Test Accuracy: 76.5625\n","Epoch 36, Loss: 0.30350208282470703, Accuracy: 87.265625, Test Loss: 0.6874654293060303, Test Accuracy: 71.25\n","Epoch 37, Loss: 0.2659302055835724, Accuracy: 88.75, Test Loss: 0.8622230291366577, Test Accuracy: 67.5\n","Epoch 38, Loss: 0.27053147554397583, Accuracy: 88.203125, Test Loss: 0.7164108753204346, Test Accuracy: 73.75\n","Epoch 39, Loss: 0.27269548177719116, Accuracy: 87.421875, Test Loss: 0.6552435159683228, Test Accuracy: 77.8125\n","Epoch 40, Loss: 0.26348793506622314, Accuracy: 89.21875, Test Loss: 0.98066645860672, Test Accuracy: 60.312496185302734\n","Epoch 41, Loss: 0.2652687430381775, Accuracy: 88.359375, Test Loss: 0.7048049569129944, Test Accuracy: 75.625\n","Epoch 42, Loss: 0.24529118835926056, Accuracy: 90.0, Test Loss: 0.7696354985237122, Test Accuracy: 76.25\n","Epoch 43, Loss: 0.2500646710395813, Accuracy: 88.671875, Test Loss: 0.9454892873764038, Test Accuracy: 73.125\n","Epoch 44, Loss: 0.2508189082145691, Accuracy: 89.53125, Test Loss: 0.7865641117095947, Test Accuracy: 77.8125\n","Epoch 45, Loss: 0.19905264675617218, Accuracy: 91.71875, Test Loss: 1.040519118309021, Test Accuracy: 75.0\n","Epoch 46, Loss: 0.2192472666501999, Accuracy: 90.15625, Test Loss: 0.7952688932418823, Test Accuracy: 78.125\n","Epoch 47, Loss: 0.25124865770339966, Accuracy: 89.765625, Test Loss: 1.0850000381469727, Test Accuracy: 61.25\n","Epoch 48, Loss: 0.19335874915122986, Accuracy: 91.875, Test Loss: 0.9694225192070007, Test Accuracy: 78.125\n","Epoch 49, Loss: 0.22454842925071716, Accuracy: 90.546875, Test Loss: 0.7690218687057495, Test Accuracy: 79.0625\n","Epoch 50, Loss: 0.21441876888275146, Accuracy: 91.015625, Test Loss: 0.6437790989875793, Test Accuracy: 76.25\n","Epoch 51, Loss: 0.18369784951210022, Accuracy: 93.125, Test Loss: 1.1299690008163452, Test Accuracy: 70.625\n","Epoch 52, Loss: 0.2020529955625534, Accuracy: 91.328125, Test Loss: 0.7871219515800476, Test Accuracy: 78.125\n","Epoch 53, Loss: 0.21198832988739014, Accuracy: 91.875, Test Loss: 0.8932313919067383, Test Accuracy: 73.125\n","Epoch 54, Loss: 0.1686372309923172, Accuracy: 93.984375, Test Loss: 0.7542445659637451, Test Accuracy: 75.0\n","Epoch 55, Loss: 0.23860731720924377, Accuracy: 92.578125, Test Loss: 0.8827923536300659, Test Accuracy: 75.9375\n","Epoch 56, Loss: 0.18181243538856506, Accuracy: 93.671875, Test Loss: 1.3595874309539795, Test Accuracy: 69.0625\n","Epoch 57, Loss: 0.1711425930261612, Accuracy: 93.125, Test Loss: 0.8665862083435059, Test Accuracy: 78.4375\n","Epoch 58, Loss: 0.14222779870033264, Accuracy: 94.453125, Test Loss: 1.1014171838760376, Test Accuracy: 78.75\n","Epoch 59, Loss: 0.14512893557548523, Accuracy: 93.828125, Test Loss: 1.3591926097869873, Test Accuracy: 74.0625\n","Epoch 60, Loss: 0.15967324376106262, Accuracy: 93.671875, Test Loss: 1.2794349193572998, Test Accuracy: 77.5\n","Epoch 61, Loss: 0.16416434943675995, Accuracy: 93.046875, Test Loss: 0.8318445086479187, Test Accuracy: 78.125\n","Epoch 62, Loss: 0.16468726098537445, Accuracy: 93.359375, Test Loss: 0.92621910572052, Test Accuracy: 78.75\n","Epoch 63, Loss: 0.18413317203521729, Accuracy: 94.375, Test Loss: 0.7662487030029297, Test Accuracy: 77.1875\n","Epoch 64, Loss: 0.08061284571886063, Accuracy: 97.03125, Test Loss: 1.0808296203613281, Test Accuracy: 79.6875\n","Epoch 65, Loss: 0.16321326792240143, Accuracy: 94.140625, Test Loss: 0.9539148211479187, Test Accuracy: 79.0625\n","Epoch 66, Loss: 0.09354931116104126, Accuracy: 96.09375, Test Loss: 1.114383339881897, Test Accuracy: 78.125\n","Epoch 67, Loss: 0.13592234253883362, Accuracy: 94.53125, Test Loss: 1.3318933248519897, Test Accuracy: 78.75\n","Epoch 68, Loss: 0.13446174561977386, Accuracy: 95.9375, Test Loss: 1.3443466424942017, Test Accuracy: 73.125\n","Epoch 69, Loss: 0.12620025873184204, Accuracy: 94.84375, Test Loss: 1.4135459661483765, Test Accuracy: 76.25\n","Epoch 70, Loss: 0.16269926726818085, Accuracy: 94.6875, Test Loss: 1.0995991230010986, Test Accuracy: 78.4375\n","Epoch 71, Loss: 0.13287144899368286, Accuracy: 95.625, Test Loss: 0.9611051678657532, Test Accuracy: 79.0625\n","Epoch 72, Loss: 0.06650304049253464, Accuracy: 97.109375, Test Loss: 1.2931950092315674, Test Accuracy: 76.25\n","Epoch 73, Loss: 0.13178999722003937, Accuracy: 95.3125, Test Loss: 1.4050867557525635, Test Accuracy: 79.0625\n","Epoch 74, Loss: 0.11724531650543213, Accuracy: 95.3125, Test Loss: 1.3979754447937012, Test Accuracy: 77.8125\n","Epoch 75, Loss: 0.1301918774843216, Accuracy: 95.546875, Test Loss: 1.5003948211669922, Test Accuracy: 75.3125\n","Epoch 76, Loss: 0.08083374053239822, Accuracy: 97.421875, Test Loss: 1.2556889057159424, Test Accuracy: 77.8125\n","Epoch 77, Loss: 0.08815581351518631, Accuracy: 97.1875, Test Loss: 1.3802635669708252, Test Accuracy: 78.125\n","Epoch 78, Loss: 0.16153588891029358, Accuracy: 95.234375, Test Loss: 1.157970666885376, Test Accuracy: 77.5\n","Epoch 79, Loss: 0.0674375593662262, Accuracy: 97.34375, Test Loss: 1.6933456659317017, Test Accuracy: 72.8125\n","Epoch 80, Loss: 0.0964924544095993, Accuracy: 96.328125, Test Loss: 1.3920546770095825, Test Accuracy: 77.8125\n","Epoch 81, Loss: 0.11177019774913788, Accuracy: 96.5625, Test Loss: 1.5771056413650513, Test Accuracy: 78.75\n","Epoch 82, Loss: 0.08769120275974274, Accuracy: 96.171875, Test Loss: 1.8791195154190063, Test Accuracy: 70.0\n","Epoch 83, Loss: 0.08444886654615402, Accuracy: 96.71875, Test Loss: 1.2504727840423584, Test Accuracy: 79.0625\n","Epoch 84, Loss: 0.11830250918865204, Accuracy: 96.171875, Test Loss: 1.1547298431396484, Test Accuracy: 79.375\n","Epoch 85, Loss: 0.04193379357457161, Accuracy: 98.59375, Test Loss: 1.4921066761016846, Test Accuracy: 78.4375\n","Epoch 86, Loss: 0.16226965188980103, Accuracy: 94.609375, Test Loss: 1.167496919631958, Test Accuracy: 78.125\n","Epoch 87, Loss: 0.1293843537569046, Accuracy: 95.625, Test Loss: 1.285142421722412, Test Accuracy: 79.0625\n","Epoch 88, Loss: 0.11933382600545883, Accuracy: 96.09375, Test Loss: 1.2247974872589111, Test Accuracy: 78.75\n","Epoch 89, Loss: 0.04209979623556137, Accuracy: 98.125, Test Loss: 1.4525753259658813, Test Accuracy: 76.875\n","Epoch 90, Loss: 0.06553155928850174, Accuracy: 97.65625, Test Loss: 1.7873766422271729, Test Accuracy: 78.4375\n","Epoch 91, Loss: 0.10371802002191544, Accuracy: 96.328125, Test Loss: 1.6668611764907837, Test Accuracy: 79.0625\n","Epoch 92, Loss: 0.0987594723701477, Accuracy: 96.40625, Test Loss: 1.5386431217193604, Test Accuracy: 78.75\n","Epoch 93, Loss: 0.07020297646522522, Accuracy: 97.34375, Test Loss: 2.4156627655029297, Test Accuracy: 75.3125\n","Epoch 94, Loss: 0.24835696816444397, Accuracy: 95.625, Test Loss: 1.6008272171020508, Test Accuracy: 77.5\n","Epoch 95, Loss: 0.03143754601478577, Accuracy: 98.828125, Test Loss: 1.9081056118011475, Test Accuracy: 78.125\n","Epoch 96, Loss: 0.08098351955413818, Accuracy: 97.34375, Test Loss: 1.646047592163086, Test Accuracy: 77.5\n","Epoch 97, Loss: 0.1058037057518959, Accuracy: 96.484375, Test Loss: 1.504689335823059, Test Accuracy: 76.25\n","Epoch 98, Loss: 0.15375648438930511, Accuracy: 95.9375, Test Loss: 1.0027393102645874, Test Accuracy: 79.0625\n","Epoch 99, Loss: 0.022766193374991417, Accuracy: 99.765625, Test Loss: 1.5544286966323853, Test Accuracy: 77.8125\n","Epoch 100, Loss: 0.16897514462471008, Accuracy: 95.78125, Test Loss: 1.326682686805725, Test Accuracy: 77.8125\n"],"name":"stdout"}]}]}